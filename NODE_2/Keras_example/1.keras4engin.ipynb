{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f802f6-4394-4bf3-8860-264c29258d4e",
   "metadata": {},
   "source": [
    "https://keras.io/getting_started/intro_to_keras_for_engineers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9bbcdc-ce0b-4e71-97a7-1fb206279640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ad86c-9dc3-40b4-b481-452ddfa20b87",
   "metadata": {},
   "source": [
    "# Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb843686-4f6c-4470-aa92-7357561835c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data loading\n",
    "Keras models accept three types of inputs:\n",
    "\n",
    "- **NumPy arrays**, just like Scikit-Learn and many other Python-based libraries. This is a good option if your data fits in memory.\n",
    "- **TensorFlow Dataset objects**. This is a high-performance option that is more suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed filesystem.\n",
    "- **Python generators** that yield batches of data (such as custom subclasses of the keras.utils.Sequence class)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be73b5-e0f3-474f-be59-917b5aed5e98",
   "metadata": {},
   "source": [
    "## Data preprocessing with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65191f09-5f6c-4fbf-bc3d-e3d8871497aa",
   "metadata": {},
   "source": [
    "This can mean:\n",
    "\n",
    "- **Tokenization** of string data, followed by token indexing.\n",
    "- **Feature normalization**.\n",
    "- **Rescaling** the data to small values (in general, input values to a neural network should be close to zero -- typically we expect either **data with zero-mean** and **unit-variance**, or data **in the [0, 1] range**.\n",
    "\n",
    "In Keras, you do in-model data preprocessing via preprocessing layers. This includes:\n",
    "\n",
    "- Vectorizing raw strings of text via the **TextVectorization** layer\n",
    "- Feature normalization via the **Normalization** layer\n",
    "- Image rescaling, cropping, or image data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af09948-3384-4f0b-9f45-7facea9de916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 5 2 9 3]\n",
      " [7 6 2 8 3]], shape=(2, 5), dtype=int64)\n",
      "['', '[UNK]', 'the', 'sample', 'this', 'is', 'heres', 'and', '2nd', '1st']\n",
      "\n",
      "[UNK]\n",
      "the\n",
      "sample\n",
      "this\n",
      "is\n",
      "heres\n",
      "and\n",
      "2nd\n",
      "1st\n"
     ]
    }
   ],
   "source": [
    "# Example: turning strings into sequences of integer word indices\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Example training data, of dtype `string`.\n",
    "training_data = np.array([[\"This is the 1st sample.\"], [\"And here's the 2nd sample.\"]])\n",
    "\n",
    "# Create a TextVectorization layer instance. It can be configured to either\n",
    "# return integer token indices, or a dense token representation (e.g. multi-hot\n",
    "# or TF-IDF). The text standardization and text splitting algorithms are fully\n",
    "# configurable.\n",
    "vectorizer = TextVectorization(output_mode=\"int\")\n",
    "\n",
    "# Calling `adapt` on an array or dataset makes the layer generate a vocabulary\n",
    "# index for the data, which can then be reused when seeing new data.\n",
    "vectorizer.adapt(training_data)\n",
    "\n",
    "# After calling adapt, the layer is able to encode any n-gram it has seen before\n",
    "# in the `adapt()` data. Unknown n-grams are encoded via an \"out-of-vocabulary\"\n",
    "# token.\n",
    "integer_data = vectorizer(training_data)\n",
    "print(integer_data)\n",
    "print(vectorizer.get_vocabulary())\n",
    "frase = vectorizer.get_vocabulary()\n",
    "for palabra in frase :\n",
    "    print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328ad76e-c409-4d69-9e1d-6f0a01b4a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]], shape=(2, 17), dtype=float32)\n",
      "['[UNK]', 'the', 'sample', 'this is', 'this', 'the 2nd', 'the 1st', 'is the', 'is', 'heres the', 'heres', 'and heres', 'and', '2nd sample', '2nd', '1st sample', '1st']\n",
      "[UNK]\n",
      "the\n",
      "sample\n",
      "this is\n",
      "this\n",
      "the 2nd\n",
      "the 1st\n",
      "is the\n",
      "is\n",
      "heres the\n",
      "heres\n",
      "and heres\n",
      "and\n",
      "2nd sample\n",
      "2nd\n",
      "1st sample\n",
      "1st\n"
     ]
    }
   ],
   "source": [
    "#  Example: turning strings into sequences of one-hot encoded bigrams\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Example training data, of dtype `string`.\n",
    "training_data = np.array([[\"This is the 1st sample.\"], [\"And here's the 2nd sample.\"]])\n",
    "\n",
    "# Create a TextVectorization layer instance. It can be configured to either\n",
    "# return integer token indices, or a dense token representation (e.g. multi-hot\n",
    "# or TF-IDF). The text standardization and text splitting algorithms are fully\n",
    "# configurable.\n",
    "vectorizer = TextVectorization(output_mode=\"binary\", ngrams=2)\n",
    "\n",
    "# Calling `adapt` on an array or dataset makes the layer generate a vocabulary\n",
    "# index for the data, which can then be reused when seeing new data.\n",
    "vectorizer.adapt(training_data)\n",
    "\n",
    "# After calling adapt, the layer is able to encode any n-gram it has seen before\n",
    "# in the `adapt()` data. Unknown n-grams are encoded via an \"out-of-vocabulary\"\n",
    "# token.\n",
    "integer_data = vectorizer(training_data)\n",
    "print(integer_data)\n",
    "print(vectorizer.get_vocabulary())\n",
    "frase = vectorizer.get_vocabulary()\n",
    "for palabra in frase :\n",
    "    print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2112b3b4-e9a0-4c96-85a7-824dfbff07f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "(5, 8, 3)\n",
      "var: 1.0000\n",
      "mean: -0.0000\n",
      "tf.Tensor(\n",
      "[[[ 0.08360337 -1.0809995   1.0775554 ]\n",
      "  [-0.41572946 -0.7288941  -1.3670094 ]\n",
      "  [-1.3064313   0.02948662 -1.5028186 ]\n",
      "  [ 1.2442149  -1.3789347   0.50715697]\n",
      "  [-0.9150623   1.2753979   0.23553862]\n",
      "  [ 0.2185582   1.5462481   1.2269455 ]\n",
      "  [-0.5641798   0.13782673  0.39850962]\n",
      "  [ 0.2185582  -0.34970376  1.4985638 ]]\n",
      "\n",
      " [[ 1.52762     1.4920781  -1.434914  ]\n",
      "  [-1.3469177   1.3701954   0.42567146]\n",
      "  [ 1.136251    0.48993206  0.11331038]\n",
      "  [ 0.87983686 -0.7559791   0.22195771]\n",
      "  [ 1.3386832   0.96392006 -0.9052583 ]\n",
      "  [ 1.2172239   0.7336973  -0.15830794]\n",
      "  [-0.9960352  -1.1622546   0.24911954]\n",
      "  [-0.05135145  0.6524422  -0.17188886]]\n",
      "\n",
      " [[ 0.3670085  -0.16010857  0.5750615 ]\n",
      "  [ 0.40749496  0.78786737 -0.17188886]\n",
      "  [ 0.25904465  0.5847297  -1.6250468 ]\n",
      "  [-1.0635127  -1.56853    -1.1361339 ]\n",
      "  [ 0.9878007   1.410823   -0.41634533]\n",
      "  [ 0.17807175  0.8555799  -0.93242013]\n",
      "  [-0.5776753   1.7087582  -1.0818102 ]\n",
      "  [-0.55068433 -0.5528414  -1.7472751 ]]\n",
      "\n",
      " [[-1.0905036   0.57118714  0.94174623]\n",
      "  [ 0.6234227  -1.0539144   0.9960699 ]\n",
      "  [ 1.4196562   0.36804944 -1.7065324 ]\n",
      "  [ 1.5411155   1.0451751   1.1047173 ]\n",
      "  [ 0.94731426 -1.0403719   0.45283327]\n",
      "  [ 0.07010789 -0.64763904 -0.5657354 ]\n",
      "  [-0.1593153   0.15136924  1.7158585 ]\n",
      "  [ 0.16457628  0.8014099  -0.52499264]]\n",
      "\n",
      " [[-0.05135145  0.1107417  -0.8916774 ]\n",
      "  [ 0.5829362  -1.0809995   1.3763355 ]\n",
      "  [ 0.78536844 -0.21427861  0.88742256]\n",
      "  [-0.36174753 -1.2435097  -1.1497148 ]\n",
      "  [ 0.42099044  1.4785355  -1.0274866 ]\n",
      "  [-0.4832069  -0.14656605  0.46641418]\n",
      "  [ 0.24554917  0.2190818  -1.5571423 ]\n",
      "  [ 1.473638   -0.02468343  1.6479539 ]]], shape=(5, 8, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example: normalizing features\n",
    "\n",
    "from tensorflow.keras.layers import Normalization\n",
    "\n",
    "# Example image data, with values in the [0, 255] range\n",
    "training_data = np.random.randint(0, 256, size=(64, 5, 8, 3)).astype(\"float32\")\n",
    "print(len(training_data))\n",
    "print(training_data[0].shape)\n",
    "\n",
    "normalizer = Normalization(axis=-1)\n",
    "normalizer.adapt(training_data)\n",
    "\n",
    "normalized_data = normalizer(training_data)\n",
    "print(\"var: %.4f\" % np.var(normalized_data))\n",
    "print(\"mean: %.4f\" % np.mean(normalized_data))\n",
    "print(normalized_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1d34d-fd6e-4791-88bb-53c7a91326ba",
   "metadata": {},
   "source": [
    "# Building models with the Keras Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b61ce7a-5d66-4835-b7b3-2050af04a0a0",
   "metadata": {},
   "source": [
    "A \"layer\" is a **simple input-output transformation** (such as the scaling & center-cropping transformations above). For instance, here's a linear projection layer that maps its inputs to a **16-dimensional feature space:**\n",
    "```python\n",
    "tf.keras.layers.Dense(\n",
    "    units,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7391cc83-343b-4391-9b25-c52e6e2e25ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.layers.core.dense.Dense'>\n"
     ]
    }
   ],
   "source": [
    "dense = keras.layers.Dense(units=16)\n",
    "print(type(dense))\n",
    "# print(dense.output_shape)\n",
    "# AttributeError: The layer \"dense_6\" has never been called and thus has no defined output shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a82ed0-cb05-4c8f-aff9-49d0c1581280",
   "metadata": {},
   "source": [
    "**Start** by **specifying** the shape (and optionally the dtype) of **your inputs**. If any dimension of your input can vary, you can specify it as None. For instance, an input for 200x200 RGB image would have shape (200, 200, 3), but an input for RGB images of any size would have shape (None, None, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0971bc17-b11d-4b12-91e7-514cb70346d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we expect our inputs to be RGB images of arbitrary size\n",
    "inputs = keras.Input(shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9c202-4ae9-4a94-8a54-b0dfce7661da",
   "metadata": {},
   "source": [
    "After defining your input(s), you can **chain layer transformations** on top of your inputs, **until** your final **output**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1032edb2-c28b-403e-892c-be6900396a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import CenterCrop\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Center-crop images to 150x150\n",
    "x = CenterCrop(height=150, width=150)(inputs)\n",
    "# Rescale images to [0, 1]\n",
    "x = Rescaling(scale=1.0 / 255)(x)\n",
    "\n",
    "# Apply some convolution and pooling layers\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "\n",
    "# Apply global average pooling to get flat feature vectors\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a dense classifier on top\n",
    "num_classes = 10\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acddbc4-91e6-4eac-8fd2-bf58f73c48f7",
   "metadata": {},
   "source": [
    "Instantiate a **Model object**:<br>\n",
    "This model behaves basically like a bigger layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2c3024-8591-4d1b-993b-8e10a7cee32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c5273b-f83b-45fc-9240-9f6f9031b71d",
   "metadata": {},
   "source": [
    "You can call it on batches of data, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64cfe525-68a6-4b25-8953-88538431a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 09:58:34.470092: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 179437568 exceeds 10% of free system memory.\n",
      "2023-08-12 09:58:35.294730: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 179437568 exceeds 10% of free system memory.\n",
      "2023-08-12 09:58:35.851387: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 179437568 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[0.07410397 0.11647474 0.10202663 0.08362741 0.11587635 0.09549182\n",
      "  0.11877757 0.0856298  0.11563359 0.09235824]\n",
      " [0.07372666 0.11657809 0.10250198 0.08331922 0.11591654 0.0955729\n",
      "  0.11870168 0.08560199 0.1153931  0.09268787]\n",
      " [0.07431979 0.11635533 0.10200357 0.08408103 0.11571723 0.09521581\n",
      "  0.11849707 0.08568646 0.11562957 0.09249421]\n",
      " [0.0739358  0.1167133  0.10225845 0.08339628 0.11575212 0.09559432\n",
      "  0.11906067 0.08545051 0.1155792  0.09225936]\n",
      " [0.07413264 0.11663312 0.10225221 0.08366787 0.1163573  0.0954052\n",
      "  0.1187713  0.08530771 0.11508706 0.09238551]\n",
      " [0.07409769 0.1164202  0.1020803  0.08357675 0.11646608 0.09532275\n",
      "  0.11825904 0.08567231 0.11578619 0.0923186 ]\n",
      " [0.07376501 0.11683293 0.10237014 0.08373573 0.1155677  0.095287\n",
      "  0.11852095 0.08582567 0.11570112 0.09239374]\n",
      " [0.07405906 0.11665686 0.10199686 0.08363652 0.11624402 0.09526346\n",
      "  0.11848207 0.08567549 0.11570782 0.09227791]\n",
      " [0.07400451 0.11665104 0.10233179 0.0834966  0.11604234 0.09538552\n",
      "  0.11842049 0.08568907 0.11548135 0.09249724]\n",
      " [0.07383379 0.11700093 0.10239367 0.08328585 0.11592647 0.09561433\n",
      "  0.11873518 0.0854733  0.11532904 0.09240742]\n",
      " [0.07370182 0.11694077 0.10204895 0.08351114 0.11575057 0.09563368\n",
      "  0.1190057  0.08538039 0.11547205 0.09255494]\n",
      " [0.07380874 0.11695921 0.10192087 0.08349513 0.11618194 0.09548052\n",
      "  0.11890515 0.08529487 0.11570301 0.09225054]\n",
      " [0.07361457 0.11656278 0.10209616 0.08357855 0.11583167 0.09526043\n",
      "  0.11900301 0.08579165 0.11590426 0.0923569 ]\n",
      " [0.07370158 0.11675113 0.10198489 0.08345971 0.11609073 0.09539082\n",
      "  0.11884314 0.0858233  0.11560132 0.0923533 ]\n",
      " [0.07415249 0.11676357 0.1024837  0.08362813 0.1158699  0.09546284\n",
      "  0.1184569  0.08547652 0.11523799 0.09246792]\n",
      " [0.0741184  0.11639567 0.10225355 0.08369051 0.11573957 0.09534293\n",
      "  0.11855002 0.08578108 0.11581189 0.09231643]\n",
      " [0.07402974 0.1168336  0.10207739 0.08341349 0.11600421 0.0955267\n",
      "  0.11860143 0.08554107 0.11561672 0.09235562]\n",
      " [0.07417094 0.11690252 0.10243716 0.08342905 0.11610738 0.09538525\n",
      "  0.11882682 0.08536617 0.11495255 0.09242214]\n",
      " [0.07391705 0.11659785 0.10192526 0.08385634 0.11601952 0.0951798\n",
      "  0.11868069 0.08565968 0.11578944 0.09237427]\n",
      " [0.07420191 0.11654245 0.10216089 0.08360583 0.11601727 0.09544946\n",
      "  0.11837337 0.08558195 0.1156097  0.09245718]\n",
      " [0.07406041 0.11654051 0.10222683 0.08362921 0.11618187 0.09535033\n",
      "  0.1183778  0.08560333 0.11556214 0.09246758]\n",
      " [0.07391535 0.11695658 0.10183617 0.08376864 0.11609836 0.09528497\n",
      "  0.11887344 0.0854154  0.11564061 0.09221034]\n",
      " [0.07389887 0.11639897 0.10233201 0.08371944 0.11591209 0.09531847\n",
      "  0.11860403 0.08554318 0.11569101 0.0925819 ]\n",
      " [0.0740348  0.11669109 0.10235391 0.08345599 0.11635145 0.09542802\n",
      "  0.11832996 0.08535443 0.11565813 0.09234221]\n",
      " [0.07395004 0.11680116 0.10204944 0.0837152  0.11598298 0.09533769\n",
      "  0.11901286 0.08527943 0.11553879 0.09233241]\n",
      " [0.07407117 0.11654204 0.10231283 0.08351809 0.11606476 0.09553149\n",
      "  0.11847617 0.08548923 0.1155441  0.09245005]\n",
      " [0.07380459 0.11667982 0.10189506 0.08371262 0.11604565 0.09533337\n",
      "  0.11874679 0.08556786 0.11584195 0.09237217]\n",
      " [0.07375319 0.11672488 0.10221392 0.08335336 0.115972   0.09545612\n",
      "  0.11911868 0.08560441 0.11549617 0.09230719]\n",
      " [0.07420274 0.1165912  0.10227413 0.08359975 0.11607548 0.09551833\n",
      "  0.11846094 0.08556633 0.11529133 0.0924198 ]\n",
      " [0.07380055 0.11675671 0.10190327 0.08370578 0.11560161 0.09521331\n",
      "  0.11902858 0.08580872 0.11599428 0.0921872 ]\n",
      " [0.07375748 0.11642971 0.10184909 0.08371859 0.11562465 0.0954534\n",
      "  0.11912896 0.08581811 0.1156991  0.09252094]\n",
      " [0.07364722 0.11664224 0.10238667 0.08375658 0.11564862 0.09513272\n",
      "  0.11899421 0.08570898 0.11568057 0.09240217]\n",
      " [0.07395486 0.11647145 0.10212881 0.08363326 0.11620707 0.09537833\n",
      "  0.11848937 0.08567654 0.11567175 0.09238852]\n",
      " [0.07405    0.11669929 0.10227586 0.08353823 0.11566984 0.09571153\n",
      "  0.118935   0.08557323 0.11491056 0.09263641]\n",
      " [0.07376996 0.11681369 0.10205293 0.08346158 0.11583503 0.09550532\n",
      "  0.11893112 0.0856595  0.11559872 0.09237207]\n",
      " [0.07401412 0.11667483 0.10232522 0.08355591 0.11586761 0.09556194\n",
      "  0.11852586 0.08558223 0.11534974 0.09254262]\n",
      " [0.07389443 0.11665191 0.10241805 0.0834826  0.11600161 0.09529921\n",
      "  0.11873912 0.08585923 0.11530758 0.09234634]\n",
      " [0.07428998 0.11669246 0.10240755 0.08364805 0.11595851 0.09552827\n",
      "  0.11852273 0.0853798  0.1149692  0.09260333]\n",
      " [0.0735821  0.11668882 0.10221776 0.08353456 0.11585986 0.09526537\n",
      "  0.11850826 0.08577649 0.11624303 0.09232373]\n",
      " [0.07404344 0.1163822  0.10157429 0.08396857 0.1161138  0.09514979\n",
      "  0.11864156 0.08544978 0.11642623 0.09225034]\n",
      " [0.07392949 0.11660005 0.10217502 0.08339823 0.11610381 0.09550209\n",
      "  0.11878129 0.0855917  0.11546638 0.09245186]\n",
      " [0.07374904 0.11685812 0.10210425 0.08359135 0.11595487 0.09525241\n",
      "  0.11913653 0.08550029 0.11557253 0.09228062]\n",
      " [0.07408538 0.11692568 0.10228242 0.08343662 0.11599722 0.09545541\n",
      "  0.1188377  0.08543638 0.11524041 0.09230275]\n",
      " [0.07420513 0.11666901 0.10234523 0.08365344 0.11638448 0.09529356\n",
      "  0.11836498 0.08524518 0.11543286 0.0924061 ]\n",
      " [0.07381887 0.11666077 0.10223127 0.08340642 0.11602196 0.09539534\n",
      "  0.11866783 0.0858454  0.11568596 0.09226615]\n",
      " [0.07383533 0.116519   0.10228592 0.08341637 0.11592425 0.09551641\n",
      "  0.11882181 0.08547743 0.11562751 0.09257599]\n",
      " [0.07413998 0.11679296 0.1022736  0.08345378 0.11593674 0.09570307\n",
      "  0.1186584  0.08552152 0.11497384 0.09254608]\n",
      " [0.07412464 0.11662187 0.10205146 0.08362621 0.11605867 0.09562518\n",
      "  0.11875216 0.08529709 0.11533745 0.0925052 ]\n",
      " [0.07382881 0.11679295 0.10188787 0.0838182  0.11581448 0.09522109\n",
      "  0.11893091 0.08558676 0.11581628 0.09230261]\n",
      " [0.07404045 0.11653214 0.10190585 0.08360595 0.11602096 0.09556733\n",
      "  0.1189034  0.08555686 0.11540692 0.09246019]\n",
      " [0.07421151 0.11637231 0.10223337 0.08369748 0.11607023 0.09553725\n",
      "  0.11822192 0.08547749 0.11546758 0.09271082]\n",
      " [0.07388596 0.11650532 0.10252982 0.08319651 0.11586019 0.09567604\n",
      "  0.11876607 0.08574885 0.11516637 0.09266485]\n",
      " [0.07383454 0.11661659 0.10198329 0.08364041 0.11601236 0.0953285\n",
      "  0.11893182 0.08551899 0.11582232 0.09231117]\n",
      " [0.07393444 0.11684781 0.10219123 0.08362422 0.11550662 0.09531508\n",
      "  0.11866141 0.08601893 0.11546006 0.09244019]\n",
      " [0.07398926 0.11640923 0.10219975 0.08356932 0.1158845  0.09544624\n",
      "  0.11855979 0.08589224 0.1155749  0.09247473]\n",
      " [0.07386329 0.11677925 0.10201073 0.08360966 0.11592459 0.09514382\n",
      "  0.1188399  0.08566088 0.11587361 0.09229422]\n",
      " [0.07380512 0.11666331 0.10211703 0.08367944 0.11574101 0.09525248\n",
      "  0.11890046 0.08567452 0.11584672 0.09231987]\n",
      " [0.07366315 0.11697017 0.1019749  0.08356517 0.11581367 0.0953904\n",
      "  0.11902257 0.08544904 0.11582755 0.09232347]\n",
      " [0.07389008 0.11682444 0.10228467 0.08340538 0.11588451 0.09542409\n",
      "  0.11879756 0.08564158 0.11548601 0.09236176]\n",
      " [0.07371377 0.11683414 0.10231594 0.08331936 0.11621821 0.09547619\n",
      "  0.11857431 0.0855213  0.1156438  0.09238309]\n",
      " [0.07377739 0.1165245  0.10195504 0.08373421 0.1158105  0.09506322\n",
      "  0.11857815 0.08593484 0.11637369 0.09224853]\n",
      " [0.074019   0.11651401 0.10235403 0.08350328 0.11595011 0.09553124\n",
      "  0.11857183 0.08555166 0.11539491 0.09260993]\n",
      " [0.0737258  0.1167005  0.10243496 0.08335383 0.11575472 0.09551131\n",
      "  0.11905217 0.08567405 0.1153494  0.09244335]\n",
      " [0.07391585 0.11652862 0.10188968 0.08363736 0.11571319 0.09539216\n",
      "  0.11914639 0.08558895 0.11598359 0.09220412]], shape=(64, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n",
    "processed_data = model(data)\n",
    "print(processed_data.shape)\n",
    "print(type(processed_data))\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f64bc9e-4576-4f98-9095-d952de44b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " center_crop (CenterCrop)    (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 49, 49, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 15, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        9248      \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 32)                0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19722 (77.04 KB)\n",
      "Trainable params: 19722 (77.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2aba2-7a22-4573-9880-9caa209770ae",
   "metadata": {},
   "source": [
    "# Training models with fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607089c-0724-44ad-9b1c-f032bc505450",
   "metadata": {},
   "source": [
    "**Before** you can call **fit()**, you **need** to specify **an optimizer and a loss function** (we assume you are already familiar with these concepts). This is the **compile()** step:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fcbd04f-4691-4563-bdc4-98d8abbd0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=keras.losses.CategoricalCrossentropy())\n",
    "# que es lo mismo que \n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f662c-05da-45de-bc52-682c090c040f",
   "metadata": {},
   "source": [
    "you can start **\"fitting\"** the model to the data. Here's what fitting a model looks like with NumPy data:\n",
    "```python\n",
    "model.fit(numpy_array_of_samples, numpy_array_of_labels,\n",
    "          batch_size=32, epochs=10)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73f188-28c7-46e8-89e7-1360ff9ae6f3",
   "metadata": {},
   "source": [
    "**Besides the data**, you have to specify **two key parameters**: the **batch_size** and the number of **epochs** (iterations on the data). Here our data will get sliced on **batches of 32 samples**, and the model will **iterate 10 times over the data during training**.\n",
    "\n",
    "Here's what fitting a model looks like with a dataset:\n",
    "```python\n",
    "model.fit(dataset_of_samples_and_labels, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8b269-5603-43c9-a74a-b4f1084fa56a",
   "metadata": {},
   "source": [
    "# LET's play with a TOY example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b327cf1c-4a1a-4f1f-9be5-89c7a9612718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " rescaling_2 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118282 (462.04 KB)\n",
      "Trainable params: 118282 (462.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Fit on NumPy data\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.2640 - accuracy: 0.9225\n",
      "Fit on Dataset\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.1146 - accuracy: 0.9657\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0746 - accuracy: 0.9772\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0528 - accuracy: 0.9844\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0391 - accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0307 - accuracy: 0.9906\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0256 - accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0226 - accuracy: 0.9929\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0186 - accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0157 - accuracy: 0.9943\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0162 - accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "# Get the data as Numpy arrays\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Build a simple model\n",
    "inputs = keras.Input(shape=(28, 28))\n",
    "x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics ='accuracy')\n",
    "\n",
    "# Train the model for 1 epoch from Numpy data\n",
    "batch_size = 64\n",
    "print(\"Fit on NumPy data\")\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1)\n",
    "\n",
    "# Train the model for 1 epoch using a dataset\n",
    "# y utiliza tensorboard para visualizar\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "print(\"Fit on Dataset\")\n",
    "history = model.fit(dataset, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcfca383-165a-4981-88e0-05a9cfb08cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.11234305053949356], 'accuracy': [0.9666666388511658]}\n",
      "<class 'keras.src.callbacks.History'>\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "print(type(history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1173a84f-b9cb-44bb-a587-3c075b48620a",
   "metadata": {},
   "source": [
    "### Keeping track of performance metrics\n",
    "#### Monitoring metrics\n",
    "#### Passing validation data to fit()\n",
    "#### Using callbacks for checkpointing (and more)\n",
    "#### Monitoring training progress with TensorBoard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2979bb-bae0-4511-9aac-eef3a064a7d9",
   "metadata": {},
   "source": [
    "## After fit(): evaluate test performance & make predictions on new data\n",
    "cuidado esto est mal. Tiene que buscar un dataset de validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6766df8-b226-4fe7-9f73-8abb9e452552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0869 - accuracy: 0.9725\n",
      "loss: 0.09\n",
      "acc: 0.97\n"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "loss, acc = model.evaluate(dataset)  # returns loss and metrics\n",
    "print(\"loss: %.2f\" % loss)\n",
    "print(\"acc: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "912ddef6-ecf4-498b-9f8e-0ab56ad22c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 8ms/step\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_dataset)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b086e-d78e-4819-be75-9af6db796318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
