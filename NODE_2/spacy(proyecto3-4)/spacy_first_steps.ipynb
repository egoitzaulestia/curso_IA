{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f16b2f-5c56-408f-814f-f5ed47f2b126",
   "metadata": {},
   "source": [
    "**spaCy’s trained pipelines** can be installed as **Python packages**. This means that they’re a component of your application, just like any other module. They’re versioned and can be defined as a dependency in your requirements.txt. Trained pipelines can be installed from a download URL or a local directory, manually or via pip. Their data can be located anywhere on your file system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62dcf8a-f2c4-4c72-ba77-ede6ab1414e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6eddac-291d-4d3a-897f-3451645707dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "7\n",
      "['We', 'are', 'learning', 'NLP', 'using', 'spaCy', '.']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"We are learning NLP using spaCy.\")\n",
    "print(type(doc))\n",
    "print(len(doc))\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070ddabd-5037-4e27-800d-2e9630358b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf9183c-549e-47f8-bbdc-ae8c9ee56b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__new__',\n",
       " '__repr__',\n",
       " '__str__',\n",
       " '__iter__',\n",
       " '__init__',\n",
       " '__len__',\n",
       " '__getitem__',\n",
       " 'set_extension',\n",
       " 'get_extension',\n",
       " 'has_extension',\n",
       " 'remove_extension',\n",
       " 'has_annotation',\n",
       " '__unicode__',\n",
       " '__bytes__',\n",
       " 'char_span',\n",
       " 'similarity',\n",
       " 'set_ents',\n",
       " 'to_array',\n",
       " 'count_by',\n",
       " '_realloc',\n",
       " 'from_array',\n",
       " 'from_docs',\n",
       " 'get_lca_matrix',\n",
       " 'copy',\n",
       " 'to_disk',\n",
       " 'from_disk',\n",
       " 'to_bytes',\n",
       " 'from_bytes',\n",
       " 'to_dict',\n",
       " 'from_dict',\n",
       " 'extend_tensor',\n",
       " 'retokenize',\n",
       " '_bulk_merge',\n",
       " 'from_json',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " '_get_array_attrs',\n",
       " '_',\n",
       " 'is_tagged',\n",
       " 'is_parsed',\n",
       " 'is_nered',\n",
       " 'is_sentenced',\n",
       " 'doc',\n",
       " 'has_vector',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'ents',\n",
       " 'noun_chunks',\n",
       " 'sents',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'vocab',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'tensor',\n",
       " 'cats',\n",
       " 'user_data',\n",
       " 'spans',\n",
       " 'sentiment',\n",
       " 'user_hooks',\n",
       " 'user_token_hooks',\n",
       " 'user_span_hooks',\n",
       " 'has_unknown_spaces',\n",
       " '_context',\n",
       " 'noun_chunks_iterator',\n",
       " '__doc__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__setstate__',\n",
       " '__hash__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__reduce_ex__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.__dir__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db3479-a85b-4c6c-a3ad-44faa7d4351b",
   "metadata": {},
   "source": [
    "https://spacy.io/usage/spacy-101<br>\n",
    "spaCy is designed specifically for production use and helps you build applications that process and “understand” large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6de77-631f-4371-9d53-82cd49739c4d",
   "metadata": {},
   "source": [
    "|NAME             |  DESCRIPTION    |\n",
    "|-----------------|-----------------|\n",
    "|1.Tokenization\t| Segmenting text into words, punctuations marks etc.|\n",
    "|2.Part-of-speech (POS) Tagging |\tAssigning word types to tokens, like verb or noun.|\n",
    "|3.Dependency Parsing\t | Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.|\n",
    "|4.Lemmatization |\tAssigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.|\n",
    "|5.Sentence Boundary Detection (SBD) |\tFinding and segmenting individual sentences.|\n",
    "|6.Named Entity Recognition (NER) |\tLabelling named “real-world” objects, like persons, companies or locations.|\n",
    "|7.Entity Linking (EL)|\tDisambiguating textual entities to unique identifiers in a knowledge base.|\n",
    "|8.Similarity |\tComparing words, text spans and documents and how similar they are to each other.|\n",
    "|9.Text Classification |\tAssigning categories or labels to a whole document, or parts of a document.|\n",
    "|10.Rule-based Matching |\tFinding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.|\n",
    "|11.Training |\tUpdating and improving a statistical model’s predictions.|\n",
    "|12.Serialization | Saving objects to files or byte strings.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3683c94-fffe-4a2c-86a0-bf38c3ccb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb7dfa-eaf7-4f3f-bfbb-94d0b4428ee1",
   "metadata": {},
   "source": [
    "# 1.Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e7671c-76a6-4e05-b519-e318e520e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      " token.text is type :<class 'str'>\n",
      " token.text[0:5] is : billi\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "print(f\" token.text is type :{type(token.text)}\")\n",
    "print(f\" token.text[0:5] is : {token.text[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551dabe9-6a47-4793-b5a4-80f022535479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apple, is, looking, at, buying, U.K., startup, for, $, 1, billion]\n"
     ]
    }
   ],
   "source": [
    "# si quiero guardarlos tengo que generarme una lista ??\n",
    "lista = []\n",
    "for token in doc:\n",
    "    lista.append(token)\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac350d-49a6-4735-8ef0-3d589a17d5d2",
   "metadata": {},
   "source": [
    "# 2.Part-of-speech tags and dependencies NEEDS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa9fc76-4758-43dc-8d3f-b70edc8b5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d2da24-62b2-4487-8dc3-bc7ba3b24a85",
   "metadata": {},
   "source": [
    "Visualizing the dependency parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab9a846-c547-4a2c-8dc0-5282ffb3c0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aee15c18222b410193a12106b692924f-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aee15c18222b410193a12106b692924f-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aee15c18222b410193a12106b692924f-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\") # he canviado 'serve' por 'render'\n",
    "# He parado el kernell pensando que se habia atascado.\n",
    "# Al parar el kernel me ha salido el esquema\n",
    "# Y el kernell inicial seguía en funcionamiento.\n",
    "# Por lo visto lanza otro kernell en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633b04fc-fcff-4506-a7c0-9999d1884c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigo teniendo kernell\n"
     ]
    }
   ],
   "source": [
    "print(\"Sigo teniendo kernell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f726a3-0c70-49b6-ab89-d6e4d91fa862",
   "metadata": {},
   "source": [
    "Visualizing the entity recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8daeb09c-9add-4313-95a5-641535c5c965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04a37b4-6478-4260-8350-cb9b2c481254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He interrumpido un Kernell, pero sigo con otro\n"
     ]
    }
   ],
   "source": [
    "print(\"He interrumpido un Kernell, pero sigo con otro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68197c4a-d1ca-44fe-86dd-852af9145467",
   "metadata": {},
   "source": [
    "Adding titles to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f02fd6-20cf-46bb-a91a-42825f3b4ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/Documents/CursoIA/Jupiter/.Jupiter/lib/python3.10/site-packages/spacy/displacy/__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<h2 style=\"margin: 0\">This is a title</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "oc = nlp(\"This is a sentence about Google.\")\n",
    "doc.user_data[\"title\"] = \"This is a title\"\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1693dc-aaf8-4a43-b258-24448fa24ca6",
   "metadata": {},
   "source": [
    "# 3.Named Entities NEEDS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33abb344-03c6-450d-8f95-0e55e3c1e7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f703b-4940-47e4-9179-e7523dbaddaa",
   "metadata": {},
   "source": [
    "Named Entity Recognition<br>\n",
    "To learn more about entity recognition in spaCy, how to add your own entities to a document and how to train and update the entity predictions of a model, see the usage guides on named entity recognition and training pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a92123-fb2c-4623-b96d-4231e5e5466c",
   "metadata": {},
   "source": [
    "# 4.Lemmatization V3.0\n",
    "https://spacy.io/usage/linguistic-features#lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cb8dad6-6bba-4d1a-bd8b-f897e935e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule\n",
      "['I', 'be', 'read', 'the', 'paper', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "print(lemmatizer.mode)  # 'rule'\n",
    "\n",
    "doc = nlp(\"I was reading the paper.\")\n",
    "print([token.lemma_ for token in doc])\n",
    "# ['I', 'be', 'read', 'the', 'paper', '.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1b27d-7db5-4f30-8bcf-e130f2a85c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d154c38-7152-4367-bb23-4ea194980603",
   "metadata": {},
   "source": [
    "# 4.Word vectors and similarity NEEDS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7bea54-c769-44b4-9b58-af4567271ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 75.254234 False\n",
      "cat True 63.188496 False\n",
      "banana True 31.620354 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b98ea3f9-e591-467f-9235-400321b8cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.691649353055761\n",
      "salty fries <-> hamburgers 0.6938489675521851\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee94a2-87d1-4516-bdb9-c5078e77487e",
   "metadata": {},
   "source": [
    "# 20.Morfology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0852b51c-cb09-4340-8bbb-04a14a01da58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "Case=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "['Prs']\n"
     ]
    }
   ],
   "source": [
    "print(\"Pipeline:\", nlp.pipe_names)\n",
    "doc = nlp(\"I was reading the paper.\")\n",
    "token = doc[0]  # 'I'\n",
    "print(token.morph)  # 'Case=Nom|Number=Sing|Person=1|PronType=Prs'\n",
    "print(token.morph.get(\"PronType\"))  # ['Prs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2bef72-7397-4d9b-a0d5-2866e0400abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.morphanalysis.MorphAnalysis'>\n"
     ]
    }
   ],
   "source": [
    "print(type(token.morph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3248df9d-ea3a-4eaa-bd31-1fb3ed6bd1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__new__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__iter__',\n",
       " '__init__',\n",
       " '__len__',\n",
       " '__contains__',\n",
       " 'from_id',\n",
       " 'get',\n",
       " 'to_json',\n",
       " 'to_dict',\n",
       " 'vocab',\n",
       " 'key',\n",
       " '__doc__',\n",
       " '__reduce__',\n",
       " '__setstate__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__reduce_ex__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.morph.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969969b0-5f13-4ce4-b5e4-4899f212472a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.morph.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29b279c5-dae2-4c27-beda-46b2c9a5e5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Case=Nom|Number=Sing|Person=1|PronType=Prs'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.morph.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87c87623-7612-4745-b86f-889e0660da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.vocab.Vocab object at 0x7fa477aee560>\n",
      "<class 'spacy.vocab.Vocab'>\n",
      "<method-wrapper '__repr__' of spacy.vocab.Vocab object at 0x7fa477aee560>\n"
     ]
    }
   ],
   "source": [
    "print(token.morph.vocab)\n",
    "print(type(token.morph.vocab))\n",
    "print(token.morph.vocab.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d630e-2da1-49a5-84d7-9705d25abddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
